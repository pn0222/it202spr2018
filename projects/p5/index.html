<!DOCTYPE html>
<html>
    <head>
        <meta charset="UTF-8">
        <title>Project 5</title>
    </head>
    
    <body>
        <video id="player" controls autoplay></video>
        <button id="capture">Capture</button>
        <canvas id="canvas" width=320 height=240></canvas>
        <canvas id="faceCanvas"></canvas>
        <canvas id="labelCanvas"></canvas>
        <div id="imageData" ></div>
        <div id="alertLabel"></div>
        <div id="alertFace"></div>
        
        
    </body>
    
    <script src="https://code.jquery.com/jquery-3.3.1.min.js"></script>
    <script>
    
        $("#canvas").hide();
        //https://vision.googleapis.com/v1/images:annotate?key=YOUR_API_KEY
        var vision = "https://vision.googleapis.com/v1/images:annotate?key=AIzaSyA70SViUQp3uyc4qKv2-IvXpPHnyubsHjk";
        const supported = 'mediaDevices' in navigator;
        const player = document.getElementById('player');
        const canvas = document.getElementById('canvas');
        const context = canvas.getContext('2d');
        const captureButton = document.getElementById('capture');
        
        const faceCanvas = document.getElementById('faceCanvas');
        const faceContext = faceCanvas.getContext('2d');
        const dataDiv = document.getElementById('imageData');
        var requestBody;
        
        
        const labelCanvas = document.getElementById('labelCanvas');
        const labelContext = faceCanvas.getContext('2d');
        
        const constraints = {
            video: true,
        };
        
        captureButton.addEventListener('click', () => {
            // Draw the video frame to the canvas.
            // context.drawImage(player, 0, 0, canvas.width, canvas.height);
            getImageData('FACE_DETECTION');
            getImageData('LABEL_DETECTION');
        });
        
        // Attach the video stream to the video element and autoplay.
        navigator.mediaDevices.getUserMedia(constraints)
        .then((stream) => {
            player.srcObject = stream;
        });
        
        function getImageData(type) {
            // capture the video frame to the hidden canvas
            
            context.clearRect(0,0,canvas.width, canvas.height);
            context.drawImage(player, 0, 0, canvas.width, canvas.height);
            
            canvas.toDataURL().split(",")[1]
             
             // create the request body
                requestBody = {
                    "requests":[{
                        "image":{
                            "content":canvas.toDataURL().split(",")[1]
                        },
                        "features":[{
                            "type": type,
                            "maxResults":10
                        }]
                    }]
                };
            
            // send the data to Google Cloud Vision
            $.ajax({
                method: "POST",
                contentType: "application/json",
                url: vision,
                data: JSON.stringify(requestBody)
            })
            .done(function(response) {
                console.log(response);
                
                // get object with face coordinates as determined by GCV
                
                if(type == "LABEL_DETECTION"){
                    if (response.responses[0].labelAnnotations != null){
                        $("#alertLabel").text("Label: " + response.responses[0].labelAnnotations[0].description);
                    }
                    else{
                        $("#alertLabel").text("No label found");
                    }
                }
                else if(type == "FACE_DETECTION"){
                    // TODO - handle "no face" condition
                    if (response.responses[0].faceAnnotations != null){
                        // find corners
                        var faceVertices = response.responses[0].faceAnnotations[0].boundingPoly.vertices;
                        console.log(faceVertices);
                        var topLeft = faceVertices[0];
                        var bottomRight = faceVertices[2];
                        console.log(bottomRight, bottomRight.x, topLeft, topLeft.x);
                        
                        // determine width and height for cropping
                        var faceWidth = bottomRight.x - topLeft.x;
                        var faceHeight = bottomRight.y - topLeft.y;
                        var sourceX = topLeft.x;
                        var sourceY = topLeft.y;
                        var destWidth = faceWidth;
                        var destHeight = faceHeight;
                   
                        //Clear data to determine if face is found
                        faceContext.clearRect(0,0,faceCanvas.width, faceCanvas.height);
                        
                        faceContext.drawImage(canvas, sourceX, sourceY, faceWidth, faceHeight, 0, 0, faceWidth, faceHeight); 
                        
                        $("#alertFace").text("Face found");
                    }
                    else{
                        $("#alertFace").text("No face found");
                        faceContext.clearRect(0,0,faceCanvas.width, faceCanvas.height); 
                    }
                }
                
                
                
            });
        
        }


    </script>
</html>
